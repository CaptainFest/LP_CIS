{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eff3f0c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration.\n",
      "/nfs/home/isaitov/miniconda3/envs/nl39/lib/python3.9/site-packages/transformers/models/trocr/processing_trocr.py:134: FutureWarning: `feature_extractor` is deprecated and will be removed in v5. Use `image_processor` instead.\n",
      "  warnings.warn(\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-large-stage1 and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-large-stage1 and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/nfs/home/isaitov/miniconda3/envs/nl39/lib/python3.9/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "/nfs/home/isaitov/miniconda3/envs/nl39/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "/nfs/home/isaitov/miniconda3/envs/nl39/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1500' max='1500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1500/1500 2:32:02, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Cer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.816800</td>\n",
       "      <td>0.665364</td>\n",
       "      <td>0.160180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.245100</td>\n",
       "      <td>0.345924</td>\n",
       "      <td>0.016624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.281000</td>\n",
       "      <td>0.282267</td>\n",
       "      <td>0.004023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.319900</td>\n",
       "      <td>0.333758</td>\n",
       "      <td>0.005234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.275400</td>\n",
       "      <td>0.291335</td>\n",
       "      <td>0.000727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.184600</td>\n",
       "      <td>0.230665</td>\n",
       "      <td>0.000291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.060500</td>\n",
       "      <td>0.370400</td>\n",
       "      <td>0.000121</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nfs/home/isaitov/miniconda3/envs/nl39/lib/python3.9/site-packages/transformers/generation/utils.py:1219: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation)\n",
      "  warnings.warn(\n",
      "/nfs/home/isaitov/miniconda3/envs/nl39/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/nfs/home/isaitov/miniconda3/envs/nl39/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'DataLoader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 148\u001b[0m\n\u001b[1;32m    145\u001b[0m trainer\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m    147\u001b[0m \u001b[38;5;66;03m# test eval\u001b[39;00m\n\u001b[0;32m--> 148\u001b[0m test_dataloader \u001b[38;5;241m=\u001b[39m \u001b[43mDataLoader\u001b[49m(test_dataset, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m)\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m tqdm(test_dataloader):\n\u001b[1;32m    150\u001b[0m     \u001b[38;5;66;03m# predict using generate\u001b[39;00m\n\u001b[1;32m    151\u001b[0m     pixel_values \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpixel_values\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'DataLoader' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "import json\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from ray import tune\n",
    "from evaluate import load\n",
    "from torch.utils.data import DataLoader\n",
    "from ray.tune.schedulers import PopulationBasedTraining\n",
    "from transformers import TrOCRProcessor, VisionEncoderDecoderModel, default_data_collator, \\\n",
    "                         Seq2SeqTrainer, Seq2SeqTrainingArguments\n",
    "\n",
    "from src.dataload import IAMDataset\n",
    "\n",
    "\n",
    "def get_names_and_np(folder:str):\n",
    "    data = []\n",
    "    for fn in os.listdir(os.path.join(folder, 'img')):\n",
    "        with open(os.path.join(folder, 'ann', f\"{fn.rsplit('.', 1)[0]}.json\"), 'r') as f:\n",
    "            js_data = json.load(f)\n",
    "            data.append([fn, js_data['description']])\n",
    "    return data\n",
    "\n",
    "def get_df_from_folder(train_folder:str, val_folder:str, test_folder:str, columns=['file_name', 'text']):\n",
    "    train_data, val_data, test_data = get_names_and_np(train_folder), \\\n",
    "                                      get_names_and_np(val_folder),   \\\n",
    "                                      get_names_and_np(test_folder)\n",
    "    train_df, val_df, test_df = pd.DataFrame(train_data, columns=columns), \\\n",
    "                                pd.DataFrame(val_data, columns=columns),   \\\n",
    "                                pd.DataFrame(test_data, columns=columns)\n",
    "    return train_df, val_df, test_df\n",
    "\n",
    "\n",
    "def update_model_config(model):\n",
    "    # set special tokens used for creating the decoder_input_ids from the labels\n",
    "    model.config.decoder_start_token_id = processor.tokenizer.cls_token_id\n",
    "    model.config.pad_token_id = processor.tokenizer.pad_token_id\n",
    "    # make sure vocab size is set correctly\n",
    "    model.config.vocab_size = model.config.decoder.vocab_size\n",
    "\n",
    "    # set beam search parameters\n",
    "    model.config.eos_token_id = processor.tokenizer.sep_token_id\n",
    "    model.config.max_length = 64\n",
    "    model.config.early_stopping = True\n",
    "    model.config.no_repeat_ngram_size = 3\n",
    "    model.config.length_penalty = 2.0\n",
    "    model.config.num_beams = 4\n",
    "    return model\n",
    "\n",
    "\n",
    "def model_init(trial):\n",
    "    model = VisionEncoderDecoderModel.from_pretrained(\n",
    "        'microsoft/trocr-large-stage1')\n",
    "    model = update_model_config(model)\n",
    "    return model\n",
    "\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    cer_metric = load('cer')\n",
    "    labels_ids = pred.label_ids\n",
    "    pred_ids = pred.predictions\n",
    "\n",
    "    pred_str = processor.batch_decode(pred_ids, skip_special_tokens=True)\n",
    "    labels_ids[labels_ids == -100] = processor.tokenizer.pad_token_id\n",
    "    label_str = processor.batch_decode(labels_ids, skip_special_tokens=True)\n",
    "    cer_metric = load(\"cer\")\n",
    "    cer = cer_metric.compute(predictions=pred_str, references=label_str)\n",
    "\n",
    "    return {\"cer\": cer}\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    dict_ocr_folders = {'Ru': '/nfs/home/isaitov/NL/data/autoriaNumberplateOcrRu-2021-09-01/',\n",
    "                        'Am': '/nfs/home/isaitov/NL/data/autoriaNumberplateOcrAm-2022-11-21-all/',\n",
    "                        'Eu': '/nfs/home/isaitov/NL/data/autoriaNumberplateOcrEu-2023-04-25/',\n",
    "                        'Kg': '/nfs/home/isaitov/NL/data/autoriaNumberplateOcrKg-2022-11-30/',\n",
    "                        'Kz': '/nfs/home/isaitov/NL/data/autoriaNumberplateOcrKz-2022-11-29/',\n",
    "                        'Su': '/nfs/home/isaitov/NL/data/autoriaNumberplateOcrSu-2023-03-10/',\n",
    "                        'Ge': '/nfs/home/isaitov/NL/data/autoriaNumberplateOcrGe-2022-11-29/',\n",
    "                        'Ua': '/nfs/home/isaitov/NL/data/autoriaNumberplateOcrUa-2023-04-18/',\n",
    "                        'Md': '/nfs/home/isaitov/NL/data/autoriaNumberplateOcrMd-2023-01-27/',\n",
    "                        'By': '/nfs/home/isaitov/NL/data/autoriaNumberplateOcrBy-2021-08-27/'}\n",
    "    \n",
    "    cer_metric = load('cer')\n",
    "    processor = TrOCRProcessor.from_pretrained(\"microsoft/trocr-large-handwritten\")\n",
    "    \n",
    "    for key in dict_ocr_folders:\n",
    "    \n",
    "        ocr_folder = dict_ocr_folders[key]\n",
    "        train_ocr_folder, val_ocr_folder, test_ocr_folder = os.path.join(ocr_folder, 'train'),  \\\n",
    "                                                            os.path.join(ocr_folder, 'val'),   \\\n",
    "                                                            os.path.join(ocr_folder, 'test')\n",
    "\n",
    "        try:\n",
    "            train_df = pd.read_csv(os.path.join(ocr_folder, 'train_df.csv'))\n",
    "            val_df = pd.read_csv(os.path.join(ocr_folder, 'val_df.csv'))\n",
    "            test_df = pd.read_csv(os.path.join(ocr_folder, 'test_df.csv'))\n",
    "        except:\n",
    "            print('Error. re-init')\n",
    "            train_df, val_df, test_df = get_df_from_folder(train_ocr_folder, val_ocr_folder, test_ocr_folder)\n",
    "            train_df.to_csv(os.path.join(ocr_folder, 'train_df.csv'), index=False)\n",
    "            val_df.to_csv(os.path.join(ocr_folder, 'val_df.csv'), index=False)\n",
    "            test_df.to_csv(os.path.join(ocr_folder, 'test_df.csv'), index=False)\n",
    "        \n",
    "        train_dataset = IAMDataset(root_dir=os.path.join(train_ocr_folder, 'img/'),\n",
    "                                   df=train_df,\n",
    "                                   processor=processor)\n",
    "        val_dataset = IAMDataset(root_dir=os.path.join(val_ocr_folder, 'img/'),\n",
    "                                   df=val_df,\n",
    "                                   processor=processor)\n",
    "        test_dataset = IAMDataset(root_dir=os.path.join(test_ocr_folder, 'img/'),\n",
    "                                   df=test_df,\n",
    "                                   processor=processor)\n",
    "        \n",
    "        training_args = Seq2SeqTrainingArguments(\n",
    "            output_dir=f'exps/aug__large_{key}',\n",
    "            predict_with_generate=True,\n",
    "            evaluation_strategy=\"steps\",\n",
    "            per_device_train_batch_size=2,\n",
    "            per_device_eval_batch_size=8,\n",
    "            load_best_model_at_end=True,\n",
    "            fp16=True,\n",
    "            logging_steps=2,\n",
    "            save_steps=1000,\n",
    "            eval_steps=200,\n",
    "            max_steps=1500\n",
    "        )\n",
    "\n",
    "        # instantiate trainer\n",
    "        trainer = Seq2SeqTrainer(\n",
    "            model=None,\n",
    "            tokenizer=processor.feature_extractor,\n",
    "            model_init=model_init,\n",
    "            args=training_args,\n",
    "            compute_metrics=compute_metrics,\n",
    "            train_dataset=train_dataset,\n",
    "            eval_dataset=val_dataset,\n",
    "            data_collator=default_data_collator,\n",
    "        )\n",
    "        \n",
    "        print(\"Running evaluation...\")\n",
    "        \n",
    "        trainer.train()\n",
    "        \n",
    "        # test eval\n",
    "        test_dataloader = DataLoader(test_dataset, batch_size=8)\n",
    "        for batch in tqdm(test_dataloader):\n",
    "            # predict using generate\n",
    "            pixel_values = batch[\"pixel_values\"].to('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "            outputs = model.generate(pixel_values)\n",
    "\n",
    "            # decode\n",
    "            pred_str = processor.batch_decode(outputs, skip_special_tokens=True)\n",
    "            labels = batch[\"labels\"]\n",
    "            labels[labels == -100] = processor.tokenizer.pad_token_id\n",
    "            label_str = processor.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "            # add batch to metric\n",
    "            cer_metric.add_batch(predictions=pred_str, references=label_str)\n",
    "\n",
    "        final_score = cer_metric.compute()\n",
    "        print(f\"Character error rate on test {key} set:\", final_score)\n",
    "        \n",
    "        # free memory\n",
    "        try: \n",
    "            trainer.model.to('cpu')\n",
    "        except:\n",
    "            pass\n",
    "        del trainer\n",
    "        gc.collect()\n",
    "        with torch.no_grad():\n",
    "            torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "91ed68f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                           | 0/356 [00:00<?, ?it/s]/nfs/home/isaitov/miniconda3/envs/nl39/lib/python3.9/site-packages/transformers/generation/utils.py:1313: UserWarning: Using `max_length`'s default (64) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 356/356 [07:14<00:00,  1.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Character error rate on test Ru set: 0.0013382402141184342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# test eval large Ru\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=8)\n",
    "for batch in tqdm(test_dataloader):\n",
    "    # predict using generate\n",
    "    pixel_values = batch[\"pixel_values\"].to('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    outputs = trainer.model.generate(pixel_values)\n",
    "\n",
    "    # decode\n",
    "    pred_str = processor.batch_decode(outputs, skip_special_tokens=True)\n",
    "    labels = batch[\"labels\"]\n",
    "    labels[labels == -100] = processor.tokenizer.pad_token_id\n",
    "    label_str = processor.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    # add batch to metric\n",
    "    cer_metric.add_batch(predictions=pred_str, references=label_str)\n",
    "\n",
    "final_score = cer_metric.compute()\n",
    "print(f\"Character error rate on test {key} set:\", final_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
